### Monitoring nodes
# Monitoring nodes are running:
#  * elasticsearch+kibana to aggregate, store and visualize logs from the nodes
#    in the cluster. By default the source of logs comes from fluentd on each
#    host.
#  * prometheus+grafana to aggregate, store and visualize live metrics from hosts
#    and containers. Source of metrics are automatically picked up from any
#    service in consul that is announced with the tag "monitor"
###

# monitoring nodes need some adjustements so that elasticsearch doesn't scream
# at us, see: https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
- hosts: monitor
  become: true
  tasks:
    - name: "Set vm.max_map_count for elasticsearch"
      sysctl:
        name: vm.max_map_count
        value: 262144
        state: present
      tags:
        - sysctl
        - monitoring

# start containers, all those containers are set to "restart_policy: unless-stopped"
# so that the user can stop those containers if they do not need/want them
- hosts: monitor
  become: true
  pre_tasks:
    - name: "Create storage directories on the host for monitoring containers"
      file:
        path: "{{ item }}"
        state: directory
        mode: 0755
      with_items:
        #- "/storage/elasticsearch/usr/share/elasticsearch/data"
        - "/storage/grafana/var/lib/grafana"
        - "/storage/prometheus/prometheus"
  roles:
    - role: AerisCloud.docker-manage
      docker_containers:
        # setup elastic search for log storage from remote fluentd instances
        - name: elasticsearch
          image: docker.elastic.co/elasticsearch/elasticsearch:5.3.2
          env:
            ES_JAVA_OPTS: "-Xms512m -Xmx512m"
            http.host: 0.0.0.0
            transport.host: 0.0.0.0
            discovery.zen.minimum_master_nodes: 1
            node.name: "{{ inventory_hostname }}"
            xpack.security.enabled: 0
          restart_policy: unless-stopped
          published_ports:
            - "9200:9200"
            - "9300:9300"
          volumes:
            - "esdata:/usr/share/elasticsearch/data"
        # setup kibana for reading those logs
        - name: kibana
          image: docker.elastic.co/kibana/kibana:5.3.2
          env:
            LOGGING_VERBOSE: "false"
            LOGGING_QUIET: "true"
          restart_policy: unless-stopped
          published_ports:
            - "5601:5601"
          links:
            - elasticsearch
        # prometheus is a time series database, provided config will scrape
        # anything tagged as monitor in consul
        - name: prometheus
          image: "prom/prometheus:master"
          restart_policy: unless-stopped
          volumes:
            # Configuration
            - "/etc/prometheus.yml:/etc/prometheus/prometheus.yml"
            - "{{ consul_client_ca_file }}:/etc/ssl/certs/consul/ca.pem:ro"
            - "{{ consul_client_cert_file }}:/etc/ssl/certs/consul/cert.pem:ro"
            - "{{ consul_client_key_file }}:/etc/ssl/certs/consul/key.pem:ro"
            # Data Volumes
            - "/storage/prometheus/prometheus:/prometheus"
          sync_templates:
            - src: "{{ playbook_dir }}/../files/monitoring/prometheus.yml"
              dest: /etc/prometheus.yml
              mode: 0644
        # graphana to read the logs from above
        - name: grafana
          image: grafana/grafana
          restart_policy: unless-stopped
          env:
            GF_SECURITY_ADMIN_USER: "{{ monitoring_user }}"
            GF_SECURITY_ADMIN_PASSWORD: "{{ monitoring_password }}"
          links:
            - prometheus
          published_ports:
            - "3000:3000"
          volumes:
            # Configuration
            - "/etc/grafana.ini:/etc/grafana/grafana.ini"
            - "/etc/grafana-ldap.toml:/etc/grafana/ldap.toml"
            - "/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem:/etc/ssl/certs/ca-certificates.crt:ro"
            # Data Volumes
            - "/storage/grafana/var/lib/grafana:/var/lib/grafana"
          sync_templates:
            - src: "{{ playbook_dir }}/../files/monitoring/grafana/config.ini"
              dest: /etc/grafana.ini
              mode: 0644
            - src: "{{ playbook_dir }}/../files/monitoring/grafana/ldap.toml"
              dest: /etc/grafana-ldap.toml
              mode: 0644
  # the following tasks will automatically provision grafana with the prometheus
  # source as well as a custom dashboard
  tasks:
    - name: "Build internal grafana URL"
      set_fact:
        grafana_url: "http://{{ group_ipv4.monitor[0] }}:3000"
      tags:
        - docker
        - grafana
    - name: "Check if prometheus source exists"
      uri:
        url: "{{ grafana_url}}/api/datasources"
        return_content: yes
        user: "{{ monitoring_user }}"
        password: "{{ monitoring_password }}"
        force_basic_auth: yes
      retries: 5
      delay: 5
      register: grafana_datasources
      until: grafana_datasources.json is defined
      tags:
        - docker
        - grafana
    - name: "Setup prometheus source on grafana"
      uri:
        url: "{{ grafana_url}}/api/datasources"
        method: POST
        user: "{{ monitoring_user }}"
        password: "{{ monitoring_password }}"
        body:
          name: prometheus
          type: prometheus
          url: http://prometheus:9090
          access: proxy
          basicAuth: false
        force_basic_auth: yes
        status_code: 200
        body_format: json
      when: "{{ 'prometheus' not in grafana_datasources.json|map(attribute='name') }}"
      tags:
      - docker
      - grafana
    - name: "Check if a dashboard exists"
      uri:
        url: "{{ grafana_url}}/api/search?query=Hardware"
        return_content: yes
        user: "{{ monitoring_user }}"
        password: "{{ monitoring_password }}"
        force_basic_auth: yes
      register: grafana_dashboards
      tags:
        - docker
        - grafana
    - name: "Register hardware dashboard"
      uri:
        url: "{{ grafana_url}}/api/dashboards/db"
        method: POST
        user: "{{ monitoring_user }}"
        password: "{{ monitoring_password }}"
        body: "{\"dashboard\":{{ lookup('file','../files/monitoring/grafana/dashboard.json') }},\"overwrite\":false}"
        force_basic_auth: yes
        status_code: 200
        body_format: json
      when: "{{ grafana_dashboards.json|length == 0 }}"
      tags:
      - docker
      - grafana
    # Finally expose the containers via consul, see https://docs.traefik.io/user-guide/kv-config/#key-value-storage-structure
    # for more information on how this works
    - name: "Expose monitoring via traefik"
      consul_kv:
        host: "127.0.0.1"
        key: "{{ item.key }}"
        value: "{{ item.value }}"
      run_once: true
      with_items:
        # kibana
        - key: "traefik/backends/kibana/servers/monitoring/url"
          value: "http://{{ group_ipv4.monitor[0] }}:5601"
        - key: "traefik/backends/kibana/servers/monitoring/weight"
          value: "1"
        - key: "traefik/frontends/kibana/backend"
          value: "kibana"
        - key: "traefik/frontends/kibana/routes/kibana/rule"
          value: "Host:kibana.{{ local_domain_name }}"
        # grafana
        - key: "traefik/backends/grafana/servers/monitoring/url"
          value: "http://{{ group_ipv4.monitor[0] }}:3000"
        - key: "traefik/backends/grafana/servers/monitoring/weight"
          value: "1"
        - key: "traefik/frontends/grafana/backend"
          value: "grafana"
        - key: "traefik/frontends/grafana/routes/grafana/rule"
          value: "Host:grafana.{{ local_domain_name }}"
