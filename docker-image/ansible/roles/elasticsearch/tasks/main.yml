- name: "Set vm.max_map_count for elasticsearch"
  sysctl:
    name: vm.max_map_count
    value: 262144
    state: present

- name: "Create logstash pipeline folder"
  file:
    path: "/etc/logstash/pipeline/"
    state: directory
    mode: 0755

- name: "Create rsyslog pipeline"
  template:
    src: "rsyslog.conf.j2"
    dest: /etc/logstash/pipeline/rsyslog.conf
    mode: 0644

- name: "Store elasticsearch template"
  copy:
    src: "elasticsearch-template.json"
    dest: /etc/logstash/elasticsearch-template.json
    mode: 0644

- name: "Start ElasticSearch version 6 or earlier on monitoring nodes"
  docker_container:
    # setup elastic search for log storage from remote fluentd instances
    name: elasticsearch
    image: "{{ elasticsearch_image }}:{{ elasticsearch_version }}"
    env:
      ES_JAVA_OPTS: "{{ elasticsearch_java_opts }}"
      http.host: 0.0.0.0
      transport.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      node.name: "{{ inventory_hostname }}"
      cluster.name: "{{ elasticsearch_cluster_name }}"
      xpack.security.enabled: "false"
    restart_policy: unless-stopped
    published_ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - "esdata:/usr/share/elasticsearch/data"
  when: elasticsearch_version is match("[56]\.\d+\.\d+")

- name: "Start ElasticSearch version 7 or later on monitoring nodes"
  docker_container:
    # setup elastic search for log storage from remote fluentd instances
    name: elasticsearch
    image: "{{ elasticsearch_image }}:{{ elasticsearch_version }}"
    env:
      ES_JAVA_OPTS: "{{ elasticsearch_java_opts }}"
      http.host: 0.0.0.0
      transport.host: 0.0.0.0
      node.name: "{{ inventory_hostname }}"
      cluster.initial_master_nodes: "{{ inventory_hostname }}"
      cluster.name: "{{ elasticsearch_cluster_name }}"
      xpack.security.enabled: "false"
      bootstrap.memory_lock: "true"
    restart_policy: unless-stopped
    ulimits:
      - "memlock:-1:-1"
    published_ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - "esdata:/usr/share/elasticsearch/data"
  when: not elasticsearch_version is match("[56]\.\d+\.\d+")

- name: "Build internal elasticsearch URL"
  set_fact:
    elasticsearch_url: "http://{{ group_ipv4.monitor[0] }}:9200"

- name: "Check if started elasticsearch"
  uri:
    url: "{{ elasticsearch_url }}/_cluster/health"
    method: GET
  retries: 6
  delay: 10
  register: elasticsearch_health
  until: elasticsearch_health.status == 200

- name: "Post elasticsearch default template"
  when: "elasticsearch_health.status == 200"
  uri:
    url: "{{ elasticsearch_url }}/_template/default"
    method: PUT
    body_format: json
    body:
      template: "*"
      order: "-1"
      settings:
        number_of_shards: "{{ elasticsearch_number_of_shards }}"
        number_of_replicas: "{{ elasticsearch_number_of_replicas }}"

- name: "Start Logstash on monitoring nodes"
  docker_container:
    # setup elastic search for log storage from remote fluentd instances
    name: logstash
    image: "{{ logstash_image }}:{{ elasticsearch_version }}"
    restart_policy: unless-stopped
    expose:
      - "9600:9600"
      - "5044:5044"
      - "1514:1514"
    published_ports:
      - "9600:9600"
      - "5044:5044"
      - "1514:1514"
    volumes:
      - "/etc/logstash/elasticsearch-template.json:/etc/logstash/elasticsearch-template.json:ro"
      - "/etc/logstash/pipeline/:/usr/share/logstash/pipeline/"
    links:
      - elasticsearch

- name: "Start Kibana on monitoring nodes"
  docker_container:
    name: kibana
    image: "{{ kibana_image }}:{{ elasticsearch_version }}"
    env:
      LOGGING_VERBOSE: "false"
      LOGGING_QUIET: "true"
      XPACK_SECURITY_ENABLED: "false"
      I18N_LOCALE: "{{ kibana_i18n_locale }}"
    restart_policy: unless-stopped
    published_ports:
      - "5601:5601"
    links:
      - elasticsearch

- name: "Install curator"
  pip:
    name: elasticsearch-curator==5.7.6
    virtualenv: /opt/dawn/deploy
    virtualenv_site_packages: yes
  when: groups['control'][0] == inventory_hostname

- name: "Install small binary to help clean old ES indices"
  template:
    src: "es_purge.sh.j2"
    dest: "/usr/local/bin/es_purge"
    mode: 0755

- name: "Setup a cron to clean up ES/Kibana logs periodically"
  when: groups['control'][0] == inventory_hostname
  cron:
    name: "purge kibana logs"
    special_time: "daily"
    job: /usr/local/bin/es_purge "logstash-" {{ log_retention }}
