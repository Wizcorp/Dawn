- name: "Set vm.max_map_count for elasticsearch"
  sysctl:
    name: vm.max_map_count
    value: 262144
    state: present

- name: "Create logstash pipeline folder"
  file:
    path: "/etc/logstash/pipeline/"
    state: directory
    mode: 0755

- name: "Create rsyslog pipeline"
  template:
    src: "rsyslog.conf.j2"
    dest: /etc/logstash/pipeline/rsyslog.conf
    mode: 0644

- name: "Store elasticsearch template"
  copy:
    src: "elasticsearch-template.json"
    dest: /etc/logstash/elasticsearch-template.json
    mode: 0644

- name: "Start ElasticSearch on monitoring nodes"
  docker_container:
    # setup elastic search for log storage from remote fluentd instances
    name: elasticsearch
    image: "{{ elasticsearch_image }}:{{ elasticsearch_version }}"
    env:
      ES_JAVA_OPTS: "{{ elasticsearch_java_opts }}"
      http.host: 0.0.0.0
      transport.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      node.name: "{{ inventory_hostname }}"
      xpack.security.enabled: 0
    restart_policy: unless-stopped
    published_ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - "esdata:/usr/share/elasticsearch/data"

- name: "Start Logstash on monitoring nodes"
  docker_container:
    # setup elastic search for log storage from remote fluentd instances
    name: logstash
    image: "{{ logstash_image }}:{{ elasticsearch_version }}"
    restart_policy: unless-stopped
    published_ports:
      - "9600:9600"
      - "1514:1514/udp"
    volumes:
      - "/etc/logstash/elasticsearch-template.json:/etc/logstash/elasticsearch-template.json:ro"
      - "/etc/logstash/pipeline/:/usr/share/logstash/pipeline/"
    links:
      - elasticsearch

- name: "Start Kibana on monitoring nodes"
  docker_container:
    name: kibana
    image: "{{ kibana_image }}:{{ elasticsearch_version }}"
    env:
      LOGGING_VERBOSE: "false"
      LOGGING_QUIET: "true"
      XPACK_SECURITY_ENABLED: "false"
    restart_policy: unless-stopped
    published_ports:
      - "5601:5601"
    links:
      - elasticsearch
